# ============================================================================
# COMPLETE RAG SYSTEM - ENVIRONMENT CONFIGURATION
# ============================================================================

# API Keys (REQUIRED - Replace with your actual keys)
PINECONE_API_KEY= your_pinecone_api_key_here
# LLM
GEMINI_API_KEY= your_gemini_api_key_here
GEMINI_MODEL=gemini-2.5-flash

# Pinecone Configuration
PINECONE_INDEX_NAME=rag-documents
PINECONE_ENVIRONMENT=us-east-1
PINECONE_CLOUD=aws

# Document Processing Limits
MAX_DOCUMENTS=20
MAX_PAGES_PER_DOC=1000
MAX_FILE_SIZE_MB=50

# Supported File Formats (comma-separated)
SUPPORTED_FORMATS=.pdf,.docx,.txt,.html,.htm,.csv,.json,.md,.xml

# Chunking Configuration
DEFAULT_CHUNK_SIZE=512
DEFAULT_CHUNK_OVERLAP=50
CHUNKING_STRATEGY=sliding_window

# Embedding Model Configuration
EMBEDDING_MODEL=all-MiniLM-L6-v2
EMBEDDING_DIMENSION=384

# OpenAI LLM Configuration
OPENAI_MODEL=gpt-3.5-turbo
OPENAI_TEMPERATURE=0.3
OPENAI_MAX_TOKENS=500
MAX_CONTEXT_CHUNKS=5

# Database Configuration
DATABASE_PATH=data/metadata.db
DATABASE_BACKUP_ENABLED=false

# Server Configuration
HOST=0.0.0.0
PORT=8000
RELOAD=false
WORKERS=1

# CORS Configuration
CORS_ALLOW_ORIGINS=*
CORS_ALLOW_CREDENTIALS=true
CORS_ALLOW_METHODS=*
CORS_ALLOW_HEADERS=*

# Logging Configuration
LOG_LEVEL=INFO
LOG_FORMAT=%(asctime)s - %(name)s - %(levelname)s - %(message)s

# Performance Configuration
EMBEDDING_BATCH_SIZE=32
PINECONE_BATCH_SIZE=100
QUERY_TIMEOUT_SECONDS=30

# Cache Configuration (Optional)
ENABLE_CACHE=false
CACHE_TTL_SECONDS=3600

# Advanced Settings
ENABLE_METRICS=false
ENABLE_PROFILING=false
DEBUG_MODE=false